{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is PyTorch?\n",
    "Code Adapted from [Deep Learning with PyTorch](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py)\n",
    "Its a Python based scientific computing package with two aspects:\n",
    "- A replacement for NumPy to use power of GPU\n",
    "- A deepLearning research platform that provide maximum flexibility and speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for correct torch installation\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Tensors\n",
    "Basic about tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.6204e-03,  5.8434e-43,  6.4894e-01],\n",
      "        [ 5.8434e-43,  5.0574e-03,  5.8434e-43],\n",
      "        [ 4.9602e+13,  0.0000e+00,  4.9601e+13],\n",
      "        [ 0.0000e+00,  1.7210e-03,  5.8434e-43],\n",
      "        [ 2.6204e-03,  5.8434e-43,  2.5703e+09]])\n"
     ]
    }
   ],
   "source": [
    "# Construct a 5x3 matrix, uninitialized\n",
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0217,  0.6115,  0.1275],\n",
      "        [ 0.6348,  0.2365,  0.5276],\n",
      "        [ 0.3702,  0.4670,  0.7611],\n",
      "        [ 0.2703,  0.4157,  0.5141],\n",
      "        [ 0.0231,  0.2657,  0.8433]])\n"
     ]
    }
   ],
   "source": [
    "# Construct a randomly initialized matrix\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0,  0],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "# Construct a matrix filled with zero and long dtype\n",
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5.,  4.,  6.])\n"
     ]
    }
   ],
   "source": [
    "# Construct a tensor directly from data\n",
    "my_lsit = [5.0, 4.0, 6.0]\n",
    "x = torch.tensor(my_lsit)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor based on existing tensor\n",
    "# Method wil reuse properties of input tensor, unless new prop are mentioned\n",
    "x = x.new_ones(5, 3, dtype=torch.double)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9584,  1.3239,  0.7512],\n",
      "        [-1.4458, -1.7208,  0.3150],\n",
      "        [-1.2228,  1.2806, -0.1146],\n",
      "        [ 0.3853, -0.0897, -0.2662],\n",
      "        [ 1.5282,  0.5504, -0.8687]])\n"
     ]
    }
   ],
   "source": [
    "# Some random methods below\n",
    "# x = torch.rand_like()\n",
    "# x = torch.randint_like()\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# To Get size of a tensor\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Operations\n",
    "Torch provides multiple syntaxes for operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4767,  0.2552,  1.1280],\n",
      "        [ 0.3544,  1.0208,  0.7070],\n",
      "        [ 0.4179,  1.0108,  0.8742],\n",
      "        [ 0.9083,  0.6209,  0.8328],\n",
      "        [ 1.5312,  1.5842,  0.7516]])\n"
     ]
    }
   ],
   "source": [
    "# Addition: Syntax 1\n",
    "x = torch.rand(5, 3)\n",
    "y = torch.rand(5, 3)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4767,  0.2552,  1.1280],\n",
      "        [ 0.3544,  1.0208,  0.7070],\n",
      "        [ 0.4179,  1.0108,  0.8742],\n",
      "        [ 0.9083,  0.6209,  0.8328],\n",
      "        [ 1.5312,  1.5842,  0.7516]])\n"
     ]
    }
   ],
   "source": [
    "# Syntax 2:\n",
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4767,  0.2552,  1.1280],\n",
      "        [ 0.3544,  1.0208,  0.7070],\n",
      "        [ 0.4179,  1.0108,  0.8742],\n",
      "        [ 0.9083,  0.6209,  0.8328],\n",
      "        [ 1.5312,  1.5842,  0.7516]])\n"
     ]
    }
   ],
   "source": [
    "# Syntax 3: providing an output tensor as argument\n",
    "result = torch.empty(5,3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4767,  0.2552,  1.1280],\n",
      "        [ 0.3544,  1.0208,  0.7070],\n",
      "        [ 0.4179,  1.0108,  0.8742],\n",
      "        [ 0.9083,  0.6209,  0.8328],\n",
      "        [ 1.5312,  1.5842,  0.7516]])\n"
     ]
    }
   ],
   "source": [
    "# Syntax 4: Addition in-place\n",
    "# any op that mutate a tensor in-place is pos-fixed with a _. eg. x.copy_(y), x.t_() will chage x.\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5070,  0.0843,  0.1304],\n",
      "        [ 0.1539,  0.4730,  0.4224],\n",
      "        [ 0.0544,  0.5346,  0.4089],\n",
      "        [ 0.8867,  0.1095,  0.3773],\n",
      "        [ 0.9627,  0.7762,  0.5023]])\n",
      "tensor([ 0.0843,  0.4730,  0.5346,  0.1095,  0.7762])\n"
     ]
    }
   ],
   "source": [
    "# Standard numpy indexing\n",
    "print(x)\n",
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3474,  0.7198,  0.9969,  0.3022],\n",
      "        [ 0.9289,  0.7644,  0.3423,  0.5764],\n",
      "        [ 0.1462,  0.9202,  0.6044,  0.5615],\n",
      "        [ 0.1613,  0.7635,  0.6305,  0.3853]])\n",
      "tensor([ 0.3474,  0.7198,  0.9969,  0.3022,  0.9289,  0.7644,  0.3423,\n",
      "         0.5764,  0.1462,  0.9202,  0.6044,  0.5615,  0.1613,  0.7635,\n",
      "         0.6305,  0.3853])\n",
      "tensor([[ 0.3474,  0.7198,  0.9969,  0.3022,  0.9289,  0.7644,  0.3423,\n",
      "          0.5764],\n",
      "        [ 0.1462,  0.9202,  0.6044,  0.5615,  0.1613,  0.7635,  0.6305,\n",
      "          0.3853]])\n",
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# To Reshape/Resize tensor, use torch.view\n",
    "x = torch.rand(4, 4)\n",
    "print(x)\n",
    "y = x.view(16)\n",
    "print(y)\n",
    "z = x.view(-1, 8)\n",
    "print(z)\n",
    "print(x.shape, y.shape, z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3351])\n",
      "0.33512961864471436\n"
     ]
    }
   ],
   "source": [
    "# if we have a 1 element tensor, use .item() to get the value as python number\n",
    "x = torch.rand(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "100+ Tensor operations, including transposing, indexing, slicing, mathematical operations, linear algebra, random numbers, etc., are described in [Official Docs](https://pytorch.org/docs/stable/torch.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## NumPy Bridge\n",
    "- We can convert a Torch Tensor to Numpy Array and ViceVersa\n",
    "- Both will share underlying memory locations and changing one will change other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Converting a torch tensor to Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  1.,  1.,  1.,  1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.,  2.,  2.,  2.,  2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# numpy arr b has changed in value\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Converting a Numpy Arr into a Torch Tensor\n",
    "- All tensors in CPU except a CharTensor support Numpy-TorchTensor convertion and back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([ 2.,  2.,  2.,  2.,  2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## CUDA Tensors\n",
    "- Tensors can be moved to any Device using `.to` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=  tensor([ 0.3351])\n",
      "tensor([ 1.3351], device='cuda:0')\n",
      "tensor([ 1.3351])\n"
     ]
    }
   ],
   "source": [
    "# Run this cell if onlt CUDA is available\n",
    "# We will use torch.device object to move tensor in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") # a CUDA device object\n",
    "    print('x= ', x)\n",
    "    y = torch.ones_like(input=x, device=device) # Directly create a tensor in GPU\n",
    "    x = x.to(device) # or use string ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.float32)) # ``.to`` can change dtype together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd: Automatic Differentiation\n",
    "Code adapted from [link](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)\n",
    "\n",
    "Central to all NN in pyTorch is Autograd package. Autograd package provide automatic differentiation to all operations done on Tensor. It is Define-by-Run framework. It means BackProp is defined by how our code is run, and each iteration can be different.\n",
    "\n",
    "[Documentation](http://pytorch.org/docs/autograd) of **autograd** and **Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Tensors\n",
    "**torch.Tensor** is central class of autograd package. If we set its attribute **.requires_grad** as **True**, it starts to track all operations on it. After finishing our computations we can call **.backward()** and have all gradient computed automatically. The gradient for this tensor will be accumulated into **.grad** attribute.\n",
    "\n",
    "To stop a tensor from tracking history, we can call **.detach()** to detach it from computation history, and to prevent future computation from being tracked.\n",
    "\n",
    "To prevent tracking history(and using memory), we can also wrap code block in **with torch.no_grad():**. This is useful when evaluating a model, bcoz the model may have trainable parameters with **requires_grad=True**, bt we dnt need gradients.\n",
    "\n",
    "Another important class for autograd implementation is **Function**\n",
    "\n",
    "**Tensor** and **Function** are interconnected and build up an acyclic graph, that encodes a complete history of computation. Each variable has a attribute called **.grad_fn** that ref to a **Function** that created the **Tensor**(except for Tensors created by the user- their **grad_fn is None**)\n",
    "\n",
    "If we want to compute the derivatives, we can call **.backward()** on a **Tensor**. If **Tensor** is a scalar(it holds one element data), u dnt need to add any argument to **.backward()**. If it has more elements, we need to specify a **gradient** argument, that is a tensor of matching shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.],\n",
      "        [ 1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor and set requires_grad=True to track computation with it.\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.,  3.],\n",
      "        [ 3.,  3.]])\n"
     ]
    }
   ],
   "source": [
    "# Do some op on Tensor\n",
    "y = torch.add(x, 2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x000001C26A4E4B00>\n"
     ]
    }
   ],
   "source": [
    "# y has grad_fn, bcoz it was created as a result of an OP\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27.,  27.],\n",
      "        [ 27.,  27.]]) tensor(27.)\n"
     ]
    }
   ],
   "source": [
    "# Do more OP on y\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x000001C27B16E4E0>\n"
     ]
    }
   ],
   "source": [
    "# .requires_grad_(...) changes an existing Tensor's requires_grad flag in-place\n",
    "# The input flag defaults to True if not given.\n",
    "a = torch.randn(2, 2)\n",
    "a = ((a*3)/ a)\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a*a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We backprop now, bcoz out has single scalar, out.backward() is equivalent to out.backward(torch.tensor(1))\n",
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.5000,  4.5000],\n",
      "        [ 4.5000,  4.5000]])\n"
     ]
    }
   ],
   "source": [
    "# print gradient d(out)/dx\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  272.7723,  1409.0833,  -832.3994])\n"
     ]
    }
   ],
   "source": [
    "# some crazy things with autograd\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  102.4000,  1024.0000,     0.1024])\n"
     ]
    }
   ],
   "source": [
    "gradients = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(gradients)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# we can also stop autograd from tracking history on Tensors with requires_grad=True\n",
    "# by wrapping code block inside with torch.no_grad():\n",
    "print(x.requires_grad)\n",
    "print((x**2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x**3).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "Code adapted from [link](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html)\n",
    "\n",
    "NN can be constructed using **torch.nn** package.\n",
    "**nn** package depends on **autograd** package to define models and differentiate them. An **nn.Module** contains layers, and a method **forward(input)** that returns the output.\n",
    "\n",
    "Below network classifies digit images:\n",
    "![ConvNet](https://pytorch.org/tutorials/_images/mnist.png \"ConvNet\")\n",
    "It is a simple feedforward ntwk. It takes input, feeds it through several layers one after other, and then finally gives output.\n",
    "\n",
    "A typical training procedure for a NN is:\n",
    "- Define a NN that has some learnable parameters(or weights)\n",
    "- Iterate over a dataset of inputs\n",
    "- Process input through the NN\n",
    "- Compute Loss(how far Output is from being correct)\n",
    "- Propagate gradients back into network's parameter\n",
    "- Update weights using update rule like:\n",
    "> weight = weight - learningRate * gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Network Definition\n",
    "We need to define **forward** function, and **backward** function(where gradients are computed) is automatically defined for us using **autograd** package. We can use any of the Tensor operations in **forward** function.\n",
    "\n",
    "The learnable parameters of a model are returned by **net.parameters()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channel, 5x5 square conv kernel\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5) # gives C1:fmaps 6@28x28\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5) # gives C3:fmaps 16@10x10\n",
    "        # Affine OP: y = Wx + b\n",
    "        self.fc1 = nn.Linear(in_features=16*5*5, out_features=120) # gives C5:layer 120\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84) # gives F6:layer 84\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=10) # gives OUTPUT 10\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Max Pooling over (2, 2) window\n",
    "        x = F.max_pool2d(input=F.relu(input=self.conv1(x)), kernel_size=(2,2))\n",
    "        # If size is a square, we can only specifiy a single number\n",
    "        x = F.max_pool2d(input=F.relu(input=self.conv2(x)), kernel_size=2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # All dim except BatchSize dim\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0885,  0.1967,  0.0459,  0.0892, -0.0083],\n",
      "          [ 0.0456,  0.1529,  0.0150, -0.0426, -0.0478],\n",
      "          [-0.1052, -0.0523,  0.1320, -0.0461,  0.1939],\n",
      "          [ 0.1467,  0.0420, -0.1992, -0.0824,  0.1449],\n",
      "          [-0.1536, -0.0131,  0.1619, -0.0567,  0.0869]]],\n",
      "\n",
      "\n",
      "        [[[-0.1682,  0.0923,  0.0188,  0.0860,  0.1887],\n",
      "          [-0.1686, -0.1491,  0.0816,  0.0187, -0.0091],\n",
      "          [-0.1819, -0.1425,  0.0610, -0.0386,  0.1105],\n",
      "          [-0.1913, -0.0793,  0.1478, -0.1136,  0.1575],\n",
      "          [-0.1666, -0.1643,  0.1953, -0.1928, -0.1068]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1316,  0.1983,  0.1328,  0.0123, -0.0181],\n",
      "          [ 0.0633,  0.0885, -0.0429, -0.0593,  0.0913],\n",
      "          [ 0.1737,  0.0736, -0.1202, -0.0569,  0.0750],\n",
      "          [ 0.0383, -0.1091,  0.0094, -0.1042, -0.0902],\n",
      "          [-0.0226,  0.1307,  0.1570, -0.0444, -0.1587]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1455,  0.0560, -0.1489, -0.0022,  0.0208],\n",
      "          [ 0.1210,  0.0313,  0.0908, -0.0637,  0.0120],\n",
      "          [ 0.0273, -0.0840,  0.0666,  0.1948, -0.1471],\n",
      "          [-0.0700,  0.0618, -0.1880, -0.1811, -0.1845],\n",
      "          [ 0.0423,  0.0901, -0.0343,  0.1199, -0.1875]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1673, -0.0194, -0.1492,  0.0823,  0.1113],\n",
      "          [-0.0712, -0.0498, -0.0781,  0.1498, -0.0070],\n",
      "          [-0.0827,  0.0824, -0.1349, -0.0666,  0.0275],\n",
      "          [-0.0481,  0.1803,  0.0790,  0.1535, -0.0569],\n",
      "          [-0.1939, -0.1549, -0.0861,  0.1669,  0.1287]]],\n",
      "\n",
      "\n",
      "        [[[-0.1385, -0.0923,  0.0185, -0.1512,  0.1521],\n",
      "          [ 0.1304,  0.1148,  0.1321,  0.1649,  0.0520],\n",
      "          [ 0.1640, -0.1041, -0.1152, -0.1136, -0.1160],\n",
      "          [ 0.0561, -0.0955,  0.1812,  0.0214,  0.0461],\n",
      "          [-0.0176, -0.1287, -0.1590, -0.1907,  0.1201]]]])\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0])\n",
    "print(params[0].size()) # conv1's weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0585, -0.0373,  0.0799, -0.1435,  0.0800, -0.0526, -0.0365,\n",
      "         -0.1645, -0.0096,  0.0617]])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn only supports mini-batches.\n",
    "# Entire torch.nn package only supports inputs that are mini-batch of samples, and nt a single sample.\n",
    "# eg. nn.conv2d will take a 4D Tensor of nSamples x nChannels x Height x Width\n",
    "# If we have a single sample, we need to use input.unsqueeze(0) to add a fake batchSize dimension.\n",
    "\n",
    "# Lets try a random 32x32 input.\n",
    "# Expected input size to this net(LeNet) is 32z32.\n",
    "# To use this net in MNIST dataset, resize images from dataset to 32x32\n",
    "input = torch.randn(1, 1, 32, 32) # nSample x nChannel x Height x Weight\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Zero the gradient buffers of all parameters\n",
    "# initialize backprops with random gradients\n",
    "net.zero_grad()\n",
    "out.backward(gradient=torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Recap:\n",
    "Lets Recap all the classes we have seen so far.\n",
    "- **torch.Tensor** - A multi-dimensional Array with support for autograd operations like **.backward()**(which holds gradient wrt the tensor).\n",
    "- **nn.Module** - Neural Network module. Convenient way of encapsulating parameters, with helpers for moving them to GPU, exporting, loading, etc.\n",
    "- **nn.Parameter** - A kind of Tensor, that is automatically registered as a parameter when assigned as an attribute to a **Module**.\n",
    "- **autograd.Function** - Implements forward and backward definitions of an autograd Operation. Every **Tensor** operation, creates at least a single **Function** node, that connects to functions that created a **Tensor** and encodes its history.\n",
    "### We covered:\n",
    "- Defining a Neural Network\n",
    "- Processing inputs and calling backward\n",
    "### Still Left:\n",
    "- Computing Loss\n",
    "- Updating weights of network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Loss Function\n",
    "- A Loss Function takes (output, target) pair of inputs, and computes a value that estimates how far away output is from target.\n",
    "- There are several different [Loss functions](https://pytorch.org/docs/stable/nn.html) under **torch.nn** package. A simple loss is **nn.MSELoss**, which computes mean-squared error btw output and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.])\n",
      "tensor([[  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.]])\n",
      "tensor(38.7923)\n"
     ]
    }
   ],
   "source": [
    "# For eg.\n",
    "output = net(input)\n",
    "target = torch.arange(start=1, end=11) # A dummy target\n",
    "print(target)\n",
    "target = target.view(1, -1) # make it same shape as output\n",
    "print(target)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now, if we follow **loss** in backward direction, using its **.grad_fn** attribute, we will see a graph of computations that looks like below.\n",
    "```\n",
    "input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
    "      -> view -> linear -> relu -> linear -> relu -> linear\n",
    "      -> MSELoss\n",
    "      -> loss\n",
    "```\n",
    "So, when we call **loss.backward()**, whole graph is differentiated wrt loss, and all Tensors in graph that has attribute **requires_grad=True** will have their **.grad** attribute accumulated with gradient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x0000016640AFDFD0>\n",
      "<AddmmBackward object at 0x0000016640AFDDA0>\n",
      "<ExpandBackward object at 0x0000016640AFDFD0>\n"
     ]
    }
   ],
   "source": [
    "# For few steps backwards:\n",
    "print(loss.grad_fn) # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0]) # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0]) # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BackProp\n",
    "- We need to clear existing gradients, else gradients will be accumulated to existing gradients.\n",
    "- To backpropagate error, we need to call loss.backward().\n",
    "- **For eg.** Lets look at conv1's bias gradient b4 and after backward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad b4 backward\n",
      "tensor([ 0.,  0.,  0.,  0.,  0.,  0.])\n",
      "conv1.bias.gradient after backward\n",
      "tensor(1.00000e-02 *\n",
      "       [ 1.0856, -5.7771, -4.8145,  1.6007,  5.6376,  0.1692])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad() # zeroes gradient buffer of all parameters of net\n",
    "\n",
    "print('conv1.bias.grad b4 backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.gradient after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Updating Weights\n",
    "Simplest Update Rule is Stochastic Gradient Descent(SGD)\n",
    "`weight = weight - learningRate * gradient`\n",
    "\n",
    "Implementing SGD in python\n",
    "```python\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)\n",
    "```\n",
    "- But in NN we need to use various different update rules like SGD, Nesterov-SGD, Adam, RMSProp, etc. Hence use the package **torch.optim** that implements all these methods.\n",
    "- Gradient Buffers has to be manually set to zero, bcoz gradients get accumulated as shown in above [BackProp](#BackProp) section. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create a optimizer\n",
    "optimizer = optim.SGD(params=net.parameters(), lr=0.01)\n",
    "\n",
    "# In Training Loop\n",
    "optimizer.zero_grad() # zero gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step() # Performs a single Update step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an Image Classifier\n",
    "[DOCS](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)\n",
    "\n",
    "When working with image, text, audio or video data, we can use standard Python packages that load data into numpy array, then we can convert this array into **torch.\\*Tensor**.\n",
    "- For image, use packages like Pillow, OpenCV\n",
    "- For Audio, use packages like SciPy and librosa\n",
    "- For text, use NLTK or SpaCy\n",
    "\n",
    "For vision, use **torchvision** package, that has **Data Loaders** for common dataset like **ImageNet, CIFAR-10, MNIST** and **Data Transformers** for images like **torchvision.datasets** and **torch.utils.data.DataLoader**.\n",
    "For this tutorial we use CIFAR10 dataset\n",
    "- It has **10 classes** viz. airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
    "- Images are **3x32x32** dim ie. 3-color channel of 32x32 pixels in size.\n",
    "\n",
    "We will do following steps:\n",
    "1. Load and normalize CIFAR10 training and test datasets using **torchvision**\n",
    "- Define a CNN\n",
    "- Define a Loss Function\n",
    "- Train network on training data\n",
    "- Test on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 1. Loading and Normalizing CIFAR10 dataset\n",
    "Output of torchvision datasets are PILImage images of range [0, 1], We transform them to Tensors of normalized range [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./dataCIFAR10\\cifar-10-python.tar.gz\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Composing different transforms into a single object\n",
    "# transforms.Normalize(mean, std); normalize each channel with mean and std\n",
    "transform = trans.Compose([trans.ToTensor(), trans.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
    "\n",
    "# training set\n",
    "trainset = torchvision.datasets.CIFAR10(root='./dataCIFAR10', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(dataset=trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "# test set\n",
    "testset = torchvision.datasets.CIFAR10(root='./dataCIFAR10', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  dog   dog  ship  ship\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztfWmQXcd13tdv32afAQaDnQBIghQlSgQpkqIthXJsylEkRSUrclwOq6yEf5yynXJVLNk/HFWlKraTku1UHKcY27GUclmylkQqlbMotBWV7EjivoIABsAAGGAw+/r2pfPjnHPPefPeACCGwmAm/VWR89D3vr59u/ved875zuK89wgICAgI2P6IbfUAAgICAgLeHoQXekBAQMAOQXihBwQEBOwQhBd6QEBAwA5BeKEHBAQE7BCEF3pAQEDADkF4oQcEBATsEGzqhe6ce8I5d8o5N+6c+8zbNaiAgICAgLcOd7OBRc65OIDTAP4ugEkAzwL4We/9G2/f8AICAgICbhSJTXz3IQDj3vtzAOCc+xKAjwLY8IWey+V8f3//Ji4ZEBAQ8P8fpqam5rz3I9c7bzMv9L0ALpl/TwJ477W+0N/fj6eeemoTlwwICAj4/w+f+9znLtzIeZuxobsubR32G+fcU86555xzz5VKpU1cLiAgICDgWtjMC30SwH7z730Arqw/yXv/tPf+hPf+RC6X28TlAgICAgKuhc280J8FcMw5d9g5lwLwKQDffHuGFRAQEBDwVnHTNnTvfcM5988A/E8AcQB/4r1//a328/nPfx4A0Gq1orZYrPN3RtrEKycej0fHarVax/eSyWRHH9KWSNBtV6vV6Jh8bjabUVsiQdfIZjOmjb5bqVQAAM6p5anRaHT00Q3yHbln24fcV71eN/3SedYj6bOf/WxbnyfHz0ef9+w5AABIZ3uitqHhXQCABx58IGob2zsGAHj99TcBAPNzS9GxlqcxJeI6j80W3Ve1qqazbDYNAEil6e/uwSG9Zj9d/+IFHduZs2cAAEtl7WNhZQUAUOC5vfvo0eiYrFm9oXM6PDwMALjzzjujtuVl6uPi+XP078XF6Jjsj2KxqPfSlLVaw3p84hd+iY/ZdZS51z3mWvRZt13TnM2fjWHS8z+c1z5invcxzzecPgcu+tzNuqloyVdlH5l9Ih+deaTsfluPWIyOxa33G3+2z5d8TqVSUdt/+ve/09bXsy+eiT7LGjjTh4xb1g4A7nvnfQCA82+8BAD4wd98x4w71jH+bvcizwk54gEO8Y5zLOQ57ObxJy31Vuczba8t82Hb1r8H4ujcT86srWyBX/v19mf7rWAzpCi8938J4C8300dAQEBAwNuDTb3Q3w6sl7wtukmuYoe39vi5uTkA7VK+SHajo6NR29DQUFu/VkI/d44ku3K53DG2NEufgEoaIpnYcYuEnk6rRC+3IMcA/eWW8VptQ/prGIm02eyU5DtgD7GUZcfWYgnDGd46EXftbeb8GIsL3kgZzXpNOtNrefrcqJGke/nyQnToxWcvAwCef/65qG1ydhYAsP/Ou/RaWVrLyYtE5BfXVqNj+/cTTTMwMKCXdDTObF7nuVqr8C002/4CQDzBUmdcJ6lW0/VYj0JvH92vWTMfzZGRylhCF+nXxeweFgm9y742EjpYQhfpvRk31zTSegdMt9KbSrDmNJHQjZTqujz28h0RoFNGmoz7Tk1B9mIyvfErxO7r6HObqkCfGw29GZmbREIk/40lXhpvpzavmgpL3tfRcDq+1wXdnlELaese1+PN/6MvAABavrXurM0hhP4HBAQE7BCEF3pAQEDADsFtY3KxEHOJVbHSaVLBCoUCACBjiMrRBJlVlpaU1OvpUUJQIESmmlo6SQ1rthFS1Kpbvb29AADxqbcmmmw2CwAYGhqM2hYWFjvuRYjVbveupK8hj1rXUucIDWteEVXTmB3qdTZJtFSlT4ipgJW9VlOPCRHbamq/QtSKCQMAfJPaWlUiHM+8/nJ07P88820AwJWrU1FbPE/r0js0HLUNjJHJZWiEAuHKhhA+e2ECALCvUYvahkZ4fo1JolQiM83S0jwAYHZ2Jjomc29NZ3A8N12mtMlz2bTHInXcquX0OTJ52GNOSC9rNuF1dJYIY9MWOs1kvqupo60rQkvsKkIGdpoO7NgcupH2YqagP01YU4CY/AwpyqdfwyiEeDxhPrOZ0ZishgaJqB8ZVrNoMknPUJyfkW5WkDYi8RrPhIu139NNQQjnLuamG02bEp3Wtrb0OWGcN1pvQ33nIKEHBAQE7BBsuYQ+Okq/0omE/lKlUyRJlcqVjrYkk5FrhjgTiT6bUaldcsbYH72FBZLgRUrt7+uNjpVZ4l5dUReqGEvmQoQCwIc+9AQA4Pz5CQDthJ9IgKIJ0HdJ2mwa6TeTab+XeEw1gFYXUjSZFIngGvKQEWWkj0hCgUpUSUMMplN0XSVHjcucSO3GXavF8+aaRkIS1z2eo8tn1FWtPEdS8n4zz0tV6qO1pi6EjgnKmhCaTZXQEyxzLCyrG2K1ThqWN+NdWCSydXmFzltbW46OiYSeSGgeIR+5jXXC8zW965So2t3M6Lwmr4sluGJ8LGZJLya3vVmDJvfX4mvGzRInfKfDQDfpO9aUa7ou50ib6dh1IRdlvHJPZu80XRcSVcZ4Db5RNFwAaDbj3L+25fOkbVsXY9GGEyzd2z2srp2mya87tv6EHyG67x3f9i86r1NzKvC9F/J57c9tXr4OEnpAQEDADkF4oQcEBATsEGy5yeXxx98HAHBGrbvzGPkoHzx4OGpzILVsaZFMLSurSoCWSmQmqVbUrxxsxkgkNZJteZV8pU+99iIA4PRJzfS7usz9dfEr72W/ZADI5UhVmp2d43NUlW216Prlso5DiE9LgFaqZJJpMjmVMX7r8TiNt8+kGRZOtlZV0896WEKlxv7iiUTVntHWFwCI5h+L1ESj2vPfhiEolTQ1ymaL1m1lheb26pWreojnr15R4lj4uNKqmsxWV8g8slyiPrxX89Qgm2vyBZ2jcxfOAgBGd2tU6lpRTGXi/20jLpnkbJl7YfI7EeuMIhS36JbRnr0XArSbOUPW1hDIbF5JWDOWmF+M2UHI7JaM0ZizHE9DLNbpzx1rM4lQv0LixtoiKXlssaZpY7OXMQfFY2IWYJOfUf9brovpJ/K7xoboFtHZdrqQ8mZKE/ycJCXK0zDT8Zj4lds4CDqvaeY0LmOPzGQm5qCrWUpp7fVQPtPeu/y15/MaGMI5tt485nWM6SRds8eY3wq5XmwWQUIPCAgI2CHYcgm9UCA3tkRCf1vWiuR6dvmK/rIeOXI3AOB99z7ILXq+uOfZX8Q6E2F1E4VWY4lx5SffDwD4nd/619Gx18dJ6nPGXVAiIm0OkG9/m1zxLl2yqeDl9E7Ssptrk5Bokhsln1MXywMHDgIAjtxxLGpLMkEkWkE3NM21o6g1I2L6KF+FJe7a//qWlWq7RB1yf7FEp5Ta4DHuv0sjQBMJ6m92+nLUNjq6h/royUZtK0xgrnJ+l4rJ81IWqd1I18uLtD+W+C8ADA+SRpPkfZRKq2YmbqqW4NV56JTQxbWu6btIbG1Su5DP9O9YF3dEZ/ZpFCyZ1GtW6jSmEpPn5bKVpOm8ZNLsSSbL7bo0eK9HWqAZo5C47btQpFQdh5X4ASBmpFrdF51uvrHqxiJ615xM5vQEJ3PxRhuo8frVWVqNZdUFOFmmfRJrqOZZ4zElY2ZfJ2T9Wnwvlux3bX8JPjraAT4Ub8Y6zrbbo7WOAG3rTbQT83qI82lHDh6I2uqNzZO5QUIPCAgI2CEIL/SAgICAHYItN7kI8ZnJ6FAmJylJ0/MvPBu1iYkjEScfbufUd/XM6VMAgHxe1fgKE4gVk4Qpzr7uzTqRdHUTvRljU4tN5OOYjLIRqIuclvVaaTu7tbWlB463R6UK0QoADz34CABgcEAJv3qZ7iWXUZ/V9UjYKD5eVmdIGMkzVaub6FG+fqMlJqDOREFNq0LyfKQSas6Is8liYJCSZ91zr5qK0s0lPl/NJel+UqGbxsQ2fYF811d4rVaLSqIWeW6GejU5VyZN8zC9qMTqAn9nqIdU9bQh2WP80fpAt67h07/I8Q+tpiXfOk0oQgyCSdykMUUlRac2poAkRz8uLqtJaWqe9lOlxoS6MQE1eY8nEzaFMZOWxnxU53vR6EobsSrqvo672RCSWMcmyeaE9M2bcSc4/sBGNUrMR+MaqaLb08t2jsPFqL9aQtdqkSOaV/ZQ9OjhD380Onb5hR8AAMpTWkfHl2jeEk01iwqbLSazlpkOuT/fbjuTD6apPe4gaROqRQSv72hz1/CBt0fuOnQHAGBk166o7bs/fB4A8CBuHkFCDwgICNghuK6E7pz7EwAfBjDjvX8Htw0C+DKAQwAmAHzSe7+4UR/Xwr3H7wUAXL6i+T4OH6K2sT2Hora9e/cCANIpyvvx2muvRseefe77AIA14wp3eYrc5yYva7+rHJ1YYMJs94gW0e7lFK4rJoIRXSK3XFe3J0K39J5yXve8LXRsZVmvOTdHRF9/n5JBEtHaqBv3v3WwUty1UvDaQhEioYl7pk3x2+Cx1evG5Usk+YaVIqmtvERFLBrzEzqmOm2JpIlMrLAL48yKaj0LfM/xDK1L3mhr4tVVqajLZpI/F5c1IjeRou80KnStXX3qapqJJECTAlUk3C61D16fphTA1m0x5jmq11mSkyVXJt2S1g2Q+y/ETaQt74WrVb3oIkcv1+ZJA+0Z2xMdS/fQ/qxVrFbF62IHzP02OAq3aWRBz1qJJcNln9r9mmuxmyBL0lXDXvZwBLQlNOs1kdpvTMmXCNSKeWwucf6fxaKu49QazcciXyzXq658mRMP0d+i7oUGu8lWz2kOobywz0nS5GKGVC6xg4NNcZ1Ok2Zvo9VT7O5crtD5V6YuRMcca7ltUrtEVneR0MWleGhQn+kH3nU/AGBySp0rJqYuY7O4EQn9TwE8sa7tMwCe8d4fA/AM/zsgICAgYAtx3Z9X7/13nXOH1jV/FMAH+PMXAHwHwK/dzACWV8memM1ap3r6ncnlVcqqValtpUXn33PvO6Nju0Z3AwB+7/c+H7VJlsOScTmssnQ4yEEqqaSV2FjKMu5b+w+QVpDIaJa+c2dJEhXJ1QZ9RD/ORpJJpdrL3gFq/0yyJJFMaR+HD5Hb4okH7o/aFq9OAwDGT6tWkuvToCvqQ6WLHOeHsFWzxIWrYop61DlQSOyg3SR0aydscY6VWk2lvUV2pZwfJ/tmuq6ulbEazXd1TaXxc5cov8tsUQcn7qT9aXLfzKR0rmTcNnePZGOMGVt+ge2xq0t0XiGux/IDktdH17bBAStdKhVisULXrFqORdzdzJzGmBvI8XgTZv7ANvGZlkqTKyxBL1d0TiuzF+meLr4GANhnuIXdebKv+qbujzrzIg2j8TkOJBNTsM1oKDliGnYd+a91FyzzfDi2r9fM5imyhpAwIrrkBEqnrvUKseOgz9MmJ89Vdld1BeWG1vi6pQZn8TRcSJpdGHv2q6Q7MkYFUB594v3aliKJ2yVI6740NRkde/XNkwCAh0+opfoOtmc7E3Un0voFlqC/+LUvRseWxGV5QcsXpiRDp3mntGT/8Lulr1/H3eB1rBuexsc3T2nerA19t/d+CgD4767rnB8QEBAQ8CPGj5wUdc495Zx7zjn3nOQQDwgICAh4+3GzMv60c26P937KObcHwMxGJ3rvnwbwNACMjY11+PXNzlDa0wMH9kdtUiji6rR2KypbItXJYp0+PQ4AOH/+QsexYlF/RMT80dtLrnB1U+xhjc0xPTklSw4dJJPLzIKmYhW1VpP3G9UXkmtCb3OQ3fmkUj0ADI+QS2KM/ekuXTDjbtE4FueUIOnrJZW00VDyaD1qJudKg00p4uLJgwMAFEtqglphElnMRzYfjJCoNgWq8Kk1Q87OzdMavXaSXEezDZ2rkQEyoRR61C1zkL/rm6qurnIemHyM1r1g8rYsrtX52np/pVUa767de6O2njyZ7CorC3xvmga5t8AquDFL+XjHVoxQr9FkGasQWhydGG+bI2pbY/NDraj3NH2JTCktY6Zo8nrHDNHsFskFb2+ezAOZlN77VSb0M2nN67MGOl6NGeK4QXMq5r+Wcc9s8v5sus4wRVuAol4VopTPM6aABJshrcklxaahbKuTBBR4Yy6ZXaLnfG5BTXLlFH03a9alp4+ejYxEJZt7SYHMaCkzf/uH6dk48a6HorYYf3eN68y+eF5TOp9l89/RuprCTuwmk611Y6406fgcn9fcfzQ6lmWX4srzSsS6ZXqW8gU1HQvpLM/ZSkPn49Ur1DZiTM3ZnJqYbxY3K6F/E8CT/PlJAN/Y9EgCAgICAjaFG3Fb/HMQATrsnJsE8JsAfgvAXzjnPg3gIoCfudkBfOsbX5HrRG1DQ/QLOH72XNRWYcJJ3BetG+DJk0R0lE0OECE10ianh5RQE9e9dFaPSe6SXuPuVuKsiefPXzQj5kIELCHZAIUmO5PZ8nEj7Br54ENKwuzZRUETF88TwXrmtVeiY9/6+pcBAMePa06UQg9JaKXKxhJ6s2VdA+m8TMZIakzMlMwcieQgATRWGvK+zn9N/hOIFKfSzRKTXGemSPKJ15W83Mfk4tCASpi9POe7ezVwamWe1naRA3TiRsORYDGb/yTKyNdGaksKPPpTNdpMuU73HDN7oWeIJGK/0impi7JTM25pkkvGcJZR1j259vKyaidzSzQv+/aqZlbI0J4szukaNNllrsnEYGFQy7EtXiSXvEJKpbg433vTPLq1lgTBcIEQ82yoAG0C5oSr61ISLWoy0rVox23nswCfjHVhlaM+9XMzIgY1QGxwoI/HqJrk8SP3AAD27hvlPoxrZZY0Plv2sVWlfdc07rgyziJnNT0/o9ruco20qDcv67vlgRVysEjF9V4qLJlfvULfLS6rtWA3S/Tv/vkno7YhzvXS16vaqLzTnnuOiuC8eV5zD03M0NgGR3UPZ9+GAhc34uXysxsc+uCmrx4QEBAQ8LYhRIoGBAQE7BBseS6XH/yQojxt1FqU/8SoiWXOzfL66+SvK8QpwXX0IW11W6CBzRISMbq0arxu2Ae1b0B9RTNZIqC8SVrfywRlmaMV6yZXjIy73xSn+MhHPgIAeOyxx6K2GptyRvhaPXklwpaXiDSqVlWtXOUUsvv2HcJGsJlJJDeLjQoVn/Oa8ZWOIga9pNbtTLdbbej8ef5cKSn5N3WVSD2fJlVzzRSzmJghE8RVk3Mlw2aP+44qCX70MH1+/RKppLMzqpr28z0njSorOU6cIekaTFq22J5QNjVcfYra+kcNObubPs+8qmaS6HyWc5yJMUiz6NMb037F5NPg/CNFpz7+dx2iiM+BrM7fUJKOFw059n0mx6r9+wAA+xPqk31oL5nrUpbkrFJ/VWNWKXE0qvia21S4VTaPJUwfSZHjuqy31NGN2UooXnz2zXwwWZ4yjvzrDYK2Hui+vWMAgJH9uu7Jvn7uS5/l++95FwBgoI/a4maN0xIPYsTQSY7RiNf1CZCI8RbHXDTn1Pc9Pk/rvWjMqCtcR3hoSM1jYoYszdJePGLiGj78vscBAA++85GorSDRpsZpQ2InDhyne/r+C6eiY9/7K3rvLS/p/ts3vHnv7yChBwQEBOwQbLmEXmMhslxWos2x9BE3UoKQkKkU/UrbWhISDWqrZkuuBuv7LhnlqlxMYHFZJU3h1CYvaya3HBN4Dz54X9Qm3lxXrxBJcvacuhyKZCTELaARogMDSgbl9xIhN7KLJLD9Jsl9mbWHak3lnUUmHrN5LYQxPatSLNCe9S4ir7pUR7fnNX17hGjVRpGydG/dBRsc+Tk3Pxu1ra6RdBN3nQU0ajxZNeMCV+TuXjunOXaGCiTlzS3RWi2ZSns+TxJMNqZaTIYzKjqjlzTYhbDJhRnqJkKzyERtune39nGNal8SdZs1EnqWXeVGM0bqHKZOFhboWqk1PbZ7lKStq+dfi9pSTOYd3Xtn1PYmayWx3ZzDJav3+e47aX9U5tUFs3Vlke9XNYUYawayh62mFefzvMm8KZlKrWOBEM0pznvSHgDNeVUMyZ7lCNFMWtt0lASrMedZw+rvVe11/x3HeRwm9wyXymvynsykTdZMWVOTZOfACM2zjbgUl9UKu+ge2KPrns3RM5008zw1Q+RzIqXkbGmZ+khw1O0HH9FI1AfvJhK1ZZ7RopQ0NFG9CX7fyF748R9TDXGZ9/r4//5K1NZvXKZvFkFCDwgICNghCC/0gICAgB2CLTe5fPjvfwwAMDmpvqID7Lc8bEiKXk6jKT6oX/nKV6NjjYaYTlTtEvOBNdtEJpcqE36VujlG542O6DV3DRNpOTqqRKkoeyn2Nb96dcYco+l8/IM/GbW9+z0nAAA1Q9p4The6skZqV9xEB951H0WkWbV5ZZl9vE16z+nv/BUsvC1szuSvDYaMs8rdMlF21eoqX4vmoa0eonw0kYANVmsXTOrbtRoTns1yRx+SWMlozUjw8WkTfXt5nq6R4TXw6Vx0bKXEJKDTa/bUSPVODuicprNEJoq/s43WXWWSbOqqmscSGTGBWXKdIOSfLQaSZtPTnSMap3BsL13ztWXqN9Gnc3VwN61poap+5dkGje3AsPbx3vsoMdSFflL3q3WN5C2X6Py0V9Pg/iE2PZpMyqU19k3nBFtN8xzEctRv0RSWWGQ7Z9xUnM+wj7ykw/VmQ0lNzkJC5zThaD7yJpJ4PZomGjOVYdLQ+HoX+HlMpLWtxQ4IQt7bmI40my9tJuo4P3PWNBiL0T03ef/tvVOLrvRxNG/LmHkkWV7LOAyIv//xe98BADh4TCNFl9mUkzRxDTk2VTVrxrmDCXTHEem9xlz32CNElE49r8/x+XGNR7lZBAk9ICAgYIdgyyX0f/pPngIAJExeiXxB0r8a5pN/3L73ve8BaCdchAxtml9pkeRtpKgSg51uerks/ao/+ojmhBjoIxKyXldiVdz/jtzBv9hOJbwiJ94fNu5HQt5Wqyqt9DCpJ38ttDiFSgv5Lueth03jG2XxtRUaeBwtM2+SvL/JErolyUQwckYrqNW4SIFxqRTXwVhMIg1t5CWX2DNS1mgfSa4141K5xJXuRapumFJujiXAfMaUveOoTbSUxIWjfsuctrZuIkVditoOxVXTimc3jnAsVkiiXzOFFLJMyPVltShKHw9pTw9dezij/R/YTeft7de9wPUw0GOeuhNZ0kbPvPAmAOCNNaUWl5N0zUM9qsH92PvI/fVAUgm28iLd6xprfNPzC9GxVV7jsbF9UVuFc/ysGrfdFqtkddA1y2Z9or3VRsSy44LdY+sQM1J+Xy9pJVZjLq8RwZtp6DOUFVdhJkdLprAJKzhtLpXz7Oabz6hWl4hzXhyeo6MHlYSWKM9sTs+X0oA2xbWMM8F/M4YwFS2w1cVNulbVd5Bohi+99BIA4J333RsdO3KALAEPf0DJ1i+dfRObRZDQAwICAnYIwgs9ICAgYIdgy00uaa5XaFWxGpNeNspTSE4xpVj1qMUqkE3wJaq/NUVUOVlPrQsp1GR1cnFR1dXeXlLL4kmj7vN4V9eor+VljYJ86L2PAgCOH787apPx2rFJxfSY60x6JPciBC6NrdnRx3q0mzoI1oQiny1ZKCl3WxGRaIhbUZeNX7mkkF0yc1RcZZJJ0p2aOU3z3N99UM0Ud4+RGuxrSv6tlelaC5wW94oJ4F1o0TxX13TcZR5bpqBmk3yc6642aO8sLKif/tIqm1zu1FiAfQ353PkI1KMKQIZAZn3/1LmrUVtPgq55YD9VmYrbWp6QalRmDdjmkowb8n6Zxjn1IlV8Ol/S/XSek70VD2hcw0994O8AAHb1qcmgwubKco5NjyWNE1heorXqSyk5O8JmyKpJwFXnoa8xgXdlzVSN4uRZbZHEkrjMb/wKmbqs0ZhH7qRnIm8qHJU5rsEZE1u8QZ/F6SBuRU4eW71hqkAt0fwVodGgz/5fisKssLnpE//w49GxQU7812aO7PJYRbWA+e+rr2q1sJ4eMsUeOnQoamswgS7vM0DfWX2c8C9hfN/jTATffb/GuAyNqr/8zSJI6AEBAQE7BFsuoUt6WUtyFqPITyPVcu6Wu++mX3r76zg1RdGdVqodYfdD28fCAldzZzelbFZ/TYeGSWKz+UEkHW82r/k1kpy74twEERjTs5qw/667KOXtgQMa+SnahpVuMnwv5S4VnPJ8LTsfcu8tGx67DvY+RVruKtGbcYj0IZG5Vrquc36SVeuiyCRW3aTg7eXx1jhXSL2mWlWWJdFdgzp/7zhMUkhv3BCaLCK9MUH9V87onC5wno1KRbeq53GuLqlUlmKSyzEpumqKozQdSYLLV/dEbdUVSd/b6bbYbHI9VSPBNpicfWViOmq7MkMpWO85SNLv2JBqAFI/MmcqzqdjNB/Nls7RlYtUfKE2x3UqTT3QNZZEkzHdTzlx9TOalmfJNcuuh8eOHIyOyUpZt+BcjiTM/btUc0pJKmmu82my1sIn2UnB5DQSLbeR3pgUHT+lbngZrv964tEfi9r2HqG6uEmo5OrEsaHBmrXdwkzcJo02v2+M7qFh9t0j7303jZufg3xWtRnPbrvdno32Nibo+Zk7z6muAS1Ws9/kpRHN15kBFwqkjd5/P9UH9kYTqfME95sI8gMHdd1uFkFCDwgICNghuJECF/sBfBHAKMgP7Wnv/e875wYBfBnAIQATAD7pvV/cqJ+NIJKrTVovsHZ1sQEfO0ZBAu9/v7r7/O3f/i2A9jJvjzxCmdBefOGFqK3Gv+LyS7yXM8ABwJE76NdRbGyAFslIGNe9GNvuC1xq6oETJ6JjR48e7Ri3SNeWDxAbep2l9zZ3Qf6ulcbFFpc3msI1IfyBlTj4szW1i2Qu11paUtv4qTffAABMXpyI2nKcByNvCoMM9pHEffEiS5iGs4hxgE7cBJ8cZHvw0RGVjJNsKM3kSIocv6que2cXl9rGCgBJtlOuGAk9ybl7ElxoAMblEOyKd3XikvbLgtGBTGeGu1qFCyQYLanOXEKzrhN47jzN18wq9T/Wr3Z7saXtgYQuAAAf9UlEQVQOG1v3rp4kt+m9r7Em5Dz9bRV1n4wM0H6+Y59KgnkO0LHcUJKzEEpum3SPXrN1mrSIF19WG/D+g0cAAAVT+m13kuy8Wc7JkzIc1TJLtZInh/5Bn1Mpq2m1o1rU4LHXXnwWADA/o9rXHccpl4totgBw6BBJ7b2sYUugE6CusTYDoxxPmj05OsBuvqztNIzWI1K75ZLk+WuT2eVB4fMff/zx6JC8P+wzHX3bWx5KSv3F+XuGv2J3zMsm6+PSuvxMN4MbkdAbAH7Ve38cwMMAftE5dw+AzwB4xnt/DMAz/O+AgICAgC3CdV/o3vsp7/0L/HkVwEkAewF8FMAX+LQvAPjYj2qQAQEBAQHXx1siRZ1zhwC8G8APAOz23k8B9NJ3zt1UdnaJprKERI4JLhstKZ8l1ebQsKbhLPSQGvrJT2q1vAfupxwMp984qX1wPpU4F4a0KlM+X+Bra4raglRit9GmHCE3xMUpdo+q2UbS7XpT31Nc4GxBDslPISTu2prm6hAS1bplSgJ+yWfTDc0u6XO7kagtMzZJUSrmLikeAgDPP0euX6U1VZt3j5Cd4sA+vefiCq3fvBDOphp9g9e0YYoD5PpJlR4eU9OWRH4ea5DpYP8ZdQ18eZpovVLTyh7Ub6WoZroaf45xFGTcpFKWghWL82qimbxMc3TgCDogqZzXDNFWb1D/Nr60lab5uFrm+qsJc/4CEftnZ9WMlYzR8axxW5zndLirDVbPjeL//kfIDfYdnE8EAMociZjImfwnTBJXS2S2aVa0/zNnxgEAlyYndRx52ke7enRP7uUcNSOc5ja9pvtkeZH2p69r9G2Kn6HENXK5tB3zTFavqEvl1Sv0rM1NayrlF3/4NwCAwV1cEGO37jWJ8hzZpa+aXiai5fkFgKaYSpPs9GDyx0TmUGuO9J1mmMiJwYsJSvuQSNGGLW7Dz1/L5P+pcm3fZX5+56/qvj53jtbl1efVJHxhXCJFlTh+q7hhUtQ5VwDwNQC/4r1fn/r4Wt97yjn3nHPuuVIXr46AgICAgLcHNyShO8qI/zUAf+a9/zo3Tzvn9rB0vgfATLfveu+fBvA0AIyNjXX4OIk0LpIpACwtLcl1ozaVpokYlMr2AHD48CEAwMc//g/0/DJJFX19KnFLd+JatLykLnkrLGkeMMUmEuyiaHiOKPlgnH/17zl+T3RMSs+lTN6H3t6ejntpci4ZcYHMmbwS7aX1CBLI0C14SO/NuC2ytFA1c5rOMLFlJPQKk60rXCprxhSukOANW0SizoFZ87N6XuQOx25piYy6oDXYze3qogYRXZwlWeDYQXUhjHMAj5SPS6hAjxi7eiWMC6GQXTWT56PEWk6swAEhGZWoWJhEw0SpVK5RYb1SImm8aiSwMufzyeVMMA67SFalAElKc7mkeR7KJkfRMhOJq7P6qFS5KEYpRhJmvaWBRYtLNFdvjKvL3OwMSfx7jMsheJ4rnAdmdVnlrVdfIdfBoiGJp64QOby3oGsVu5uyPiZcZ74eKf+YNBkKExJsF9v4FeJM2bsEu2+2TAm/TA89J1kTbDQzRftpkffYhZNati3NGm22oM4BqQI9GznjMCDPixSESWXN+dxH0pTOg7jrtgUmMgnOz2rDZEsV5wr7zqqVaY+Xi7p+8k5ZZQm9uqzabpO1naUV1RoTmc07HV63B0dvij8GcNJ7/3lz6JsAnuTPTwL4xqZHExAQEBBw07gRCf19AH4ewKvOuZe47dcB/BaAv3DOfRrARQA/86MZYkBAQEDAjeC6L3Tv/ffQNdsBAOCDmx2AqC22nqUQF5boE5JQjkk0KQDs3k2RerYqeXGZVJp9+zQPRjrzMl+TVCapO2r7bdgq9y1SCW29wtPjpwEAY+wbfPSopuaU/qwqJvcgphdqa48elYgye592PoQUbbal62xHyxn/V84jYtxeo7wkjZaqvCtcv/TSDJFSS2VV1QsyXpO2VoifK1dVTSzVmSSWyFzjN1yvUv9zppDIq5coqvfYQRNVmaC1ml0lNTue1HvJckV7S1BWapx7pmF89YsrfJ/UV6LNH57mN9+jhSXuOMpEY5fgW9G8C4YMT6WYaG7ovpu5Qj7e5SWKHvVVjYMosA95rl/NMKkMqf6NuJrVUgUih7MFOq9s7nN8ktalaNT9LO+x0Wn15x7tp7bBfIbvU/eamPDiRTVRri7RPJ85rXvhniNkahxlwnvJ5ChaWqHvDvao6ULMUa64MS8WswaAGDsMmFdOcYXMZD27DEHOr5omr6MzBHLDS2EYHVujSPfStA4AQnJKUY/mtV9z8pg0W5YUFZMLr3vTHIt8zk0bF/xIpI1ZSshZNlUlzfMV4+ek10RRp/r0PXCzCJGiAQEBATsEW57LRaROm4dFIres26JI0OIpMzExER2TKu3ijggAvUyGPvLwe6O2V9iFcY0l04995CPaP5NviyZa0rNkPnlR82CcYjewj32cLEx9feo+KbAuh/LZGRIuw4SZFL0Q101AyRp770IIXyvbopXeG/y5YaQWz+J6w5w3yRLgG2+Su9TKqpI2nl0Zc+ZePEu9FaOx9AwTOZfKkXRRNWXHPBNmVeMOdnmernFyQt3ohlOcIXGVrlmqGmmLh1svq8biEkQi20hYqfBe40rsyaRKPrUaR37O6xrMnCKi8dCxTr/FNJfCa9SMZCz5d0wBCr9K5GZlkfbHREnJzliBtIGccafrZXfBpqkMP8jk7ZH9pEkODqprquOiDfWEapJSP2F3Xs87cAdpiwfZrdRqLlGuJJMx9PJVGu/LLynZevcdFKE5eoD68mZuhVxfWTUEOWsvsZje3/rd2TRFMvYdIg0g16ua2RyTw71GE8qyVFuW4iWGRG3xPmqa+xNS1rqpOpaI5ZmO2ahQdGY4hY9HR6NrtURCb/I1OzOi2mhdsItmLGUldJ4jbqqtaSSovKssN9/ooi2+VQQJPSAgIGCHILzQAwICAnYIttzkIqYWSwKKaaFliytwgqBlTueaz5sagmwWWDOmC7G+FAwZ+fDDVC90jYmcUZOcS/zaT589G7W98golNJq+on7XfYNEXlU5fej4uYnoWD9Hcg4PK8mzygUg5heUSEyzn/p6tW4jzMzMcl+rG55jNcimEDqG8RMVc3FRzSpvnnkdAHBhnMi90oohm9iEUTJ6tCTFipu0w0n2ZS6xWl4ztVOlcnrVkHqXZ+kaL55Sk8u+PupvgSMST5+1xSkkmtWozWmyO1g1W4juBE9l06R6LXN90dySSQB3iW0XWhA+QiMyMSjhF2dOsV7S+WtxCtQ4E1y+acjwIpnultd076wKWd0yxSP4u4fuOgQAKJqiGmUeR6pfTS5g80ulbsyLOdp3Az1k/rPxFWKqPHJUq9YvrtDYTi9ohOalKxM0Ho4/SCd0vh2bP0plJVarVU4iZzae7nq+NxM1uXsPmXL6h9R/fmGGTC7nz56L2voKZNpKZTixm/HjXx+9yXfITZ1Rns04rXE9Vus4Zqwwuh5e51ScI0r8rrCPqOzxbE7J7R6umZo1tV6T/G6L4hoaalpybK5ZWTL7w0SM3yyChB4QEBCwQ7DlEroQfjYKUtqsC6EIYz0cGfb+H/9AdGycperpq1p8YP9+qnKeMFGbhQIXQeDIsPFzSgpJJNjlK5pvYWqK+ltZ1l/OXXuo39PjdM2sOX8/S/zWhSrFUm2sTZpsd9W0uVzaU3KCx0SS1LVSJzS7EKBN47dYZrJy+rJKZadOEsFb5vtrGXfLJI+3VlOpVkipvHGzlMykUt6vbqIrk0wU1U3q2ytz1F/D3PP0IK3L3AwRjhOXVEJf4bwktYaJ4muU+NqmCj27qIlbn1EK0OJ91GMksKO5jVMRS1m9unFVE2bLGRmowHlpYqwO+preU56FsYaR2iUPS2lJNaH5adLcxuskNc8aqbYYo3tZmlOi3qVp/y/2Kbn4wBhpjWN9nVHJOdagWqbNsUYbs+Xxku3S71C/araH99P5NTO2EmuoDhvncsmZfDNxvn46rpp1X540ikvTKqXOLJN2keMoz6R5fpNMVqcNiSoRqO2povmP70wZLe8Z+75R90rto8EM5SKntLUSeqRZGxfTRpVOKKR13mTbeyFUW9p/nV15m0WTftg8OzeLIKEHBAQE7BCEF3pAQEDADsGWm1wENrpSVBrbJuROhquzHDumVU6iaE1DlkjaWluFW9LW9nIkXaGgauulixTBODyokX0Zrsz98oumNiITgjVOzGRNHefPielHzRoDXDPQ+tnL/SX4npZM0p4Gm1yaTUto8u1dIzmX9S8XUrRhCLZ59q+fMFV71lbpHuKsNjeN77sk5YoZsqnGvukJE6Wb4aRIOZ6rsvE9bnF/PqlrUOIlHZ9T4u7SZVJraxX6bqmkqmyLZY62SD2OivVmveNMMiU4IVTNzF/kZVzWflcvECE3+DA60NtDJGOqZc2AZOZp1NTEkMsPcP9M4pu6p315Ps+YXCQEdbql/uqLy7Qulzlat2iKeTIfjNVV4/ueoPm+klbTxbMDtLdSntZncFDV/vkFMmdMTGka6bPnJ2ho5v5KrO4Xq/S3WtFxSNxG3ThK19mckbCZ1NYhFjMmGnZmKKf1mauWaP+ljI+8JIWrF3kcJo1vs0nnZ7JqyukdJDIylbZxLGweYzOd9RdPxLrIsFFFI1MVi33TOV8cUjY5HHfXKOvaLq6RybEnr3M/PEQmuRa/ixLOEs1SfUn7dW7zr+MgoQcEBATsEGy5hD41xXlEjKuVwLrpicQqRR6sxLtnD6VilQg/Op9+4fv6NH+HpLUtMLH62GMfiI6dHZ8AALz8sroiXbhI7lS9JgXv8AhJ8I6lxJaRgmtcb7JlCD8hMnMmLa7UJY1JLU2TU6anj+5v0bg5Vrl4w7UiRROmjmmLJYGVoo5jcYm0gNU1JVYTnF+jWOV0xUbbaLGkBBP56VhDqKzYyFZ2ZeR7qRriVirDo6HSZJrHWW+qlLXCklqD16zNpSySwq10w3+NPOKbNDdlnquaSfUq9TGThlgtLm5cCzMi401hBJn7rKkgn/EkbTbZna8OJZCT7F6YTZt153so5vW81bwUc+Fr1tQ1MC5up03ViKQIQ8OIYrP87FzhyMuG1/7PTRDxPTWve0G0QBfTZ2i1TGv1+hmqcTm+qPMtNVOLZV3bIrvu2Uhpm9AXaI8cPXeaNIQzb6iLYplTXA8NaB8SHQsuaOKMFiF5VUqm/nBrma4yaDVrjsQWUr7tsVmXQpvA51kJnZ+FYa4xnMupI8Ai17m1BWSW+F1VNPu/r7fO5/OzbJ6lfJbGmDL7Kd4IpGhAQEBAAGPLJfSTJ+mX2/7qit07b1zLxFaXZxvVntHR6JgUiFha0gx04qtk7fB1CdTgfCm23JdIuNb9Kc/9PvKI5oMZGZHyV5KFTX9Vm9Gvv0Kub3OzJNneF2fJsVJTabFUoXmwv/7dsk+uR9yU+6rWqb/pOXX/K66QlNcwtmXPblQtto22bHAXS4xWapc8GM2Knrc8TVJhPCm5KWxpL2pbXTKFKNgd0laV93F2rWuRdGMz7IlWAGtDl4+WUuDPNc8chMnrk2jR3KRSKmXF8yZYZx1E+7M2Y+Evqube42JfTZEUHmvosQZzCVZiS8Y7bbVx3uvCGzTMXpC8PmlTrAMJOj+ZUcl/hQt9rHAJukGvGuV6t1K6Bu3FgWEt5VYYpPJuJ8+Txjy5pmNsppknMVJqPM3ZFjdWGmHqiaDGAVm1sukX8oyqlNrL2SnLEtRl9nxMslSazKJ1dgm8clldlmXeermcXl+/jjtviskIJCtjzNizS6yNaGZW8xywHd4W2ZFgwYzh7CJeS0oxmj08t0DzYV2A09mNXWlvFEFCDwgICNghCC/0gICAgB2C65pcnHMZAN8FkObzv+q9/03n3GEAXwIwCOAFAD/vva9t3FN3THI0piWbYqxW9pniAGN7SCUU80rW1K68cPECAKBkSNQRTiVaM6qmRD2ucjTaK6+8FB27eOEin6+mnwyrUbZYQomjCPOsfra8iS7j/CE+3anOl02OkxabLnbz/VnzysoKqWJW/fNdIt7WI27qMpaYWKubKu0N/lwxrlYlztcixFOr1WnWsORRZDAw7oKezTuSgjRhyGrH5GzdFNWIXFLrnVXXHavg7YU55EM33d6kNOUvSU0DWyQjkaHvruZUfZ/I0md1flVILciFNSUjsxz12JuxRVHoYgnQXlgsakSnRP+mWjrfGSa8Cz2a+nZphcwIy832ggqAqXtpyMskmz/SWVXVW2yKqHk6f2pax7G4yGSdIcNbTDjWTErYC1fIXFnoo+fLJ5WojAK2TSpbJxGa8RuTCSUo1btOM5bseQDIcj6awUFy+VtZNGZDdpe1WWtTTDpnMvr+kLTUS+wIUK3pvYs5t8cUAUmzyaxa1fOmpq7y2Gj+bP0MIchXTaGNnt7+tnsC1HVaXJehy475+XkemyFC3wbx+ka6qAJ43Hv/LgD3A3jCOfcwgN8G8Lve+2MAFgF8evPDCQgICAi4WdxICToPQHyekvyfB/A4gH/E7V8A8C8B/OFbHcAqS0G2EIBkcLPZzCSIZJZds2ImQGCeq9XnMkoqSP6TuXklSyQI6DxL4+ms/kr3DdIvbE+//oy2mNQ4dVKDMuYX2MWPJehek1ND3NwahkxrtjqJzDhnjlzjX/8eI7Fl0+LGZkhUlgotKVpptOd1yRsJRQKs4oawlcIMVVP9vSnaC4tgNt9Mi4lYI1xrsJG5biySqtmdzuSiEUnGEs0JJm+tViIEohHeOvpo5z9FfTCujLwfJDgjk1Iicc8ordGRY/uitqFRJQTX48oUBZmtmdwl6TUuIzasa5XkoKEGl9rr6dE16GGCK9JgAFSYUF02bq0StNPDBTFswr0GS9zWxTOf5cIZBXUSrDbo+MIy999QiTeTZTffhO6XNSbe0yaQZWCECmy4NEnG8/Oqqa7VmFCHrm2Tg4aaRgM5biRQoF17Ff2u7nU+ZHbtus/NUBbO/F5Kg3n0juPRsSUOkrp4SV0flyukWdj8LikukuFi1PGacd+dXyDJuLBqC4/w3K+oRiYaluxrq5VKIJRtk60YjxkCOwoIpPNSxoV1ZJRcrW2WWash3CxuSMh3zsW5QPQMgG8DOAtgyfvICXsSwN4NvvuUc+4559xz10ouFRAQEBCwOdzQC9173/Te3w9gH4CHABzvdtoG333ae3/Ce38i18VlKCAgICDg7cFb8kP33i85574D4GEA/c65BEvp+wBcuZkBZFlV6i2ouWRsjNLQ7h3bo9dm00U3v27xDa8bn3PESL2ZnlVS5dRpSpcrKpNN2H/gANc8ND86cfaptv63r73+BgDgNBeFOHpM/U6Hhom4teRlgk0zMeMnLiphnSMpK2YckQ9+XudD8tfYnBQXihpJCgDvufdd0eerM7QUcyanTJMJ0Ka5lmtIvURRpY0Jg1XktujUKMOqrekohK2kCG2tPx1tnvnxzt99LVQhOVo6z7lWHhs+AYDmckk5k7+D72FkSEn2Rx89AQCYONtpEuvn6OKcMUE1uUiGjV4uLZA5b22ZTX6GiO3NSN4gs45M/OcLauoTE1urSf3HTS1UMNnpTNtKSZzfdT4SbP5YWKI1HunRPekc7fWWSd2aER92M0drHK27ssjFVKpmv2aoj3TGpK3lAhTJtJEJi5qjBtAcRADgeQ/ETERzmuMU4ja/ChOJkxfP0LXN+ffeeQ8A4OCeQ1Hbm+deAwBcntEcRQtFjjpnO0jCyK0yC8UlzY9TWamsO7puTABgIsJjbKrKmUIvfUx4502t11hcao9y3hZzL3Eek8011WxuXuC9roTunBtxzvXz5yyAnwBwEsBfA/gEn/YkgG9sejQBAQEBATeNG5HQ9wD4gnMuDvoB+Avv/becc28A+JJz7l8BeBHAH9/MAB579BEAwIDJ5yAujA1bQV5c21yn5Ch5MOaNi1OB3ZIGBpU82rfvEAAlVFdWlSwREtVKxkLm5Y2EPraPJPkmT13OSFvy+2iFWrlWG+EoKTokt0dRCagEu2zu2aOkXSbLRJ/5Nb8wcQYWD9z3Tj02SWOaGH8zarvohcRSYqvOWo5Eu3pLMkbytWnrQnJinauhlaRdxwfAs1bQJm/7jg966HqSeXQeE09cqGF0l0pKo7tpTVtN1Wrm5oVYO9jRV5mjNctVm++F+l1dUCm0vkyfa2WS2htGWl1eIqnPX9YCKHtGSIOzs1cSkroubp+61+pNLv5i3AWHhongTRqpPc3S8gBnHjwwNhwde5Ezhda8cYNNcMSvkdrz7ICw9wCVijs/bfIoMdGXTGsf/exEUMgr0YdTL8MicruESuhJM440P0PWwUEKvKzWSds4e/5VPcaRsPceU230wXc8CgDou3gqaptYIKeHUpHIYV/SdbRkvEKyMppcLjx22eqNhr6Lenopv8vggOaJqiPVdj5gSjCy22TcuHimu7g2x7plgnyLuBEvl1cAvLtL+zmQPT0gICAg4DZAiBQNCAgI2CHY8uRcB1jFq5pEN0X2G11eVuJCXB4lyVDN1POLcyKmgon+Ep/zw4ePRG29vaSunp8gdbtqUpWucf9FQxpKIYyeHlWtRjlVr2eys1K16WUlyY+SH1G6U+Ob3mDzRyYl0XZ6fpGrjM+axFp3HjsEoD1F6HqsrSyazxQpWDd+rQ2+V5v8SVmrTvOKjPsauZfovKiKehfTiJjHun+xo49rpQfuBnu+mFzSWWq787j6nN9/P1W8T2V1z9SqEk3ZaXLpyXH61ZiNJ6DPuWE1ZzSZmFxbI3U7m9Z1LOTJPLayqFGbs7NEODpTxEKSwlXKHOlqyH4fq/M4dK4ynNTMquw5NslNc5GM0688Fx2bniE/7aY34ZVs/suZaNNyiUws+QqZKbIZPb8RZ9OI9oDVJdpvjbL6bm+8O4G6EO8Nu0/Yx9uYGjwT44lkvO3fADB5mZ7b+Vk1ex05TP7q+V69l4PZOwAAxQq9Rypr6pcv75SySQXsOb7DjkOetRTHMyws6jUlAnpkt+6FeU7HXDNmLDFNyrsrmeokpttMlG7z8nWQ0AMCAgJ2CNyNkk5vB8bGxvxTTz11y64XEBAQsBPwuc997nnv/YnrnRck9ICAgIAdgvBCDwgICNghCC/0gICAgB2C8EIPCAgI2CG4paSoc24WQBHA3PXOvc0xjO19D9t9/MD2v4ftPn5g+9/Ddhr/Qe/9yPVOuqUvdABwzj13I2zt7Yztfg/bffzA9r+H7T5+YPvfw3YffzcEk0tAQEDADkF4oQcEBATsEGzFC/3pLbjm243tfg/bffzA9r+H7T5+YPvfw3YffwduuQ09ICAgIOBHg2ByCQgICNghuKUvdOfcE865U865cefcZ27ltW8Gzrn9zrm/ds6ddM697pz7ZW4fdM592zl3hv8ObPVYrwUu8v2ic+5b/O/Dzrkf8Pi/7KRO2W0K51y/c+6rzrk3eS0e2YZr8M95D73mnPtz51zmdl4H59yfOOdmnHOvmbauc+4I/46f61ecc+/ZupErNriHf8P76BXn3H+Vamx87LN8D6eccz+1NaPeHG7ZC50rHv0BgA8BuAfAzzrn7rlV179JNAD8qvf+OKiO6i/ymD8D4Bnv/TEAz/C/b2f8MqhsoOC3Afwuj38RwKe3ZFQ3jt8H8D+893cDeBfoXrbNGjjn9gL4JQAnvPfvABAH8Cnc3uvwpwCeWNe20Zx/CMAx/u8pAH94i8Z4PfwpOu/h2wDe4b1/J4DTAD4LAPxcfwrAvfyd/8DvrG2FWymhPwRg3Ht/zntfA/AlAB+9hdd/y/DeT3nvX+DPq6AXyV7QuL/Ap30BwMe2ZoTXh3NuH4C/B+CP+N8OwOMAvsqn3O7j7wXw4+ASh977mvd+CdtoDRgJAFnnXAJADsAUbuN18N5/F8DCuuaN5vyjAL7oCd8HFZDfgy1Gt3vw3v8vLmwPAN8HFbgH6B6+5L2veu/PAxjHNqzIditf6HsBXDL/nuS2bQHn3CFQKb4fANjtvZ8C6KUPYNfG39xy/B6AfwFElQKGACyZTX27r8MdAGYB/Gc2G/2Rcy6PbbQG3vvLAP4tgIugF/kygOexvdYB2HjOt+uz/QsA/jt/3q730IZb+ULvVo5mW7jYOOcKAL4G4Fe89yvXO/92gXPuwwBmvPfP2+Yup97O65AA8B4Af+i9fzcodcRta17pBrY1fxTAYQBjAPIgM8V63M7rcC1stz0F59xvgEyqfyZNXU67re+hG27lC30SwH7z730ArtzC698UnHNJ0Mv8z7z3X+fmaVEp+e/MRt/fYrwPwEeccxMgE9fjIIm9n1V/4PZfh0kAk977H/C/vwp6wW+XNQCAnwBw3ns/672vA/g6gEexvdYB2HjOt9Wz7Zx7EsCHAfycV7/tbXUPG+FWvtCfBXCMmf0UiID45i28/lsG25v/GMBJ7/3nzaFvAniSPz8J4Bu3emw3Au/9Z733+7z3h0Dz/Vfe+58D8NcAPsGn3bbjBwDv/VUAl5xzd3HTBwG8gW2yBoyLAB52zuV4T8k9bJt1YGw0598E8I/Z2+VhAMtimrnd4Jx7AsCvAfiI975kDn0TwKecc2nn3GEQwfvDrRjjpuC9v2X/AfhpELN8FsBv3Mpr3+R4HwOpXa8AeIn/+2mQHfoZAGf47+BWj/UG7uUDAL7Fn+8AbdZxAF8BkN7q8V1n7PcDeI7X4b8BGNhuawDgcwDeBPAagP8CIH07rwOAPwfZ++sg6fXTG805yFzxB/xcvwry5rld72EcZCuX5/k/mvN/g+/hFIAPbfX4b+a/ECkaEBAQsEMQIkUDAgICdgjCCz0gICBghyC80AMCAgJ2CMILPSAgIGCHILzQAwICAnYIwgs9ICAgYIcgvNADAgICdgjCCz0gICBgh+D/AX5XQAY/EyI1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# function to show image\n",
    "def imshow(img):\n",
    "    img = img/2 + 0.5 # unnormalize\n",
    "    np_img = img.numpy()\n",
    "    plt.imshow(X=np.transpose(a=np_img, axes=(1, 2, 0)))\n",
    "\n",
    "# get some random training images\n",
    "iter_data = iter(trainloader)\n",
    "images, labels = iter_data.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# Print labels\n",
    "print(' '.join('%5s' % classes[labels[index]] for index in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 2. Define a CNN\n",
    "We can use same NN from above [Neural Network > Network Definition](#Network-Definition) section and modify it to take 3-channel images(instead of 1-channel images as it was defined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(in_features=16*5*5, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 3. Define a Loss function and optimizer\n",
    "Lets use a Classification Cross-Entropy Loss and SGD with momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(params=net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 4. Train the network\n",
    "We simply need to loop over our data iterator, and feed the inputs to network and optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.189\n",
      "[1,  4000] loss: 1.876\n",
      "[1,  6000] loss: 1.698\n",
      "[1,  8000] loss: 1.599\n",
      "[1, 10000] loss: 1.544\n",
      "[1, 12000] loss: 1.487\n",
      "[2,  2000] loss: 1.390\n",
      "[2,  4000] loss: 1.375\n",
      "[2,  6000] loss: 1.359\n",
      "[2,  8000] loss: 1.331\n",
      "[2, 10000] loss: 1.325\n",
      "[2, 12000] loss: 1.274\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): # Loop over dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print stats\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999: # print every 2000 mini-batch\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss/2000))\n",
    "            running_loss = 0.0\n",
    "print('Finished training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 5. Test network on test data\n",
    "We trained network for 2 passes over training dataset. But we need to check if the network has learned anything.\n",
    "\n",
    "We will check this by predicting class label that neural netowrk outputs, and checking it against Ground-Truth. If prediction is correct, we add the sample to list of correct predictions.\n",
    "\n",
    "Lets display an image from test set to get familiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth:    cat  ship  ship plane\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iter_data = iter(testloader)\n",
    "images, labels = iter_data.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('Ground Truth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:    cat   car   car  ship\n"
     ]
    }
   ],
   "source": [
    "# TO check wat NN thinks of these images are\n",
    "output = net(images)\n",
    "\n",
    "# The outputs are energies for 10 classes.\n",
    "# Higher energy for a class, the more the network thinks that the image is of a particular class.\n",
    "# So lets get the index of highest energy\n",
    "_, predicted = torch.max(output, 1) # torch.max(inputtensor, dimtoconsider)\n",
    "print('predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc of net on 10,000 test images: 53 %\n"
     ]
    }
   ],
   "source": [
    "# To look at performance of net in whole dataset\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Acc of net on 10,000 test images: %d %%' % (100 * correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "That is an okay Accuracy. Not bad, btr than chance, which is 10% Acc(randomly picking a class out of 10 classes). Seems like the net has learned something.\n",
    "\n",
    "What are the classes that performed well, and classes that did not?:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc of plane : 66 %\n",
      "Acc of   car : 77 %\n",
      "Acc of  bird : 50 %\n",
      "Acc of   cat : 27 %\n",
      "Acc of  deer : 49 %\n",
      "Acc of   dog : 52 %\n",
      "Acc of  frog : 46 %\n",
      "Acc of horse : 63 %\n",
      "Acc of  ship : 54 %\n",
      "Acc of truck : 52 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Acc of %5s : %2d %%' % (classes[i], 100*class_correct[i]/class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Training on GPU\n",
    "Just like transfering Tensor on to GPU, we can transfer NN also to GPU.\n",
    "\n",
    "Lets 1st define our device as first visible CUDA device if we have CUDA available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# if we are in a CUDA machine, this should print a CUDA device\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The rest of this section will assume that device is a CUDA device\n",
    "\n",
    "# These methods will recursively go over all modules and convert their parameters and buffers to CUDA tensors\n",
    "net.to(device)\n",
    "\n",
    "# Remember that we need to send inputs and targets at every step to GPU\n",
    "inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "# Why dont we see a massive speedUp compared to CPU? bcoz the above NN is really small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals Achieved:\n",
    "- Understanding PyTorch Tensor library and NN at higher level\n",
    "- train a small NN to classify Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
